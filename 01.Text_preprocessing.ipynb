{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cfc6ea-fc43-4fdb-a845-2ed56fc63c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f91737-c7b7-4e17-88f9-f50e65b20c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20695ba4-bcc2-4a4e-83f2-0345c60ef5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c481b56-f35b-4ecd-b761-5c70cc2399d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c04cf4-2c6b-4c94-96c8-af1d6359a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf19903-06eb-4093-82f8-9f1e851def86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5b73859-3a3a-4e23-8268-5bf2dbca855f",
   "metadata": {},
   "source": [
    "#### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68827a-9236-46d6-aa2a-c0f483014973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8562719c-1e01-4a5b-85e7-2a0561621fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. the plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). while some may be disappointed when they realize this is not match point 2: risk addiction, i thought it was proof that woody allen is still fully in control of the style many of us have grown to love.<br /><br />this was the most i\\'d laughed at one of woody\\'s comedies in years (dare i say a decade?). while i\\'ve never been impressed with scarlet johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />this may not be the crown jewel of his career, but it was wittier than \"devil wears prada\" and more interesting than \"superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][2].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871628da-4325-4af0-ab08-171cc647e84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd11e2b-3ee5-470d-9ace-5a635d834d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d0b775-00fb-4b60-b553-aa6e544fccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]=df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4132e6cf-7278-48e1-9ee9-1e4fc129464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a0210-9958-4664-9535-c788f823ef07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a60e7de9-84d6-48c4-bc07-adcc1ea954fe",
   "metadata": {},
   "source": [
    "#### Removing HTML tags by regular experission ie regex or use online tools for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc40f5c4-5161-4589-ba4e-ecd003df9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')  #### search for this pattern online \n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ff9397b-fc32-419c-9269-c06206ecbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='<br /><br />this was the most i\\'d laughed at one of woody\\'s comedies in years '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ca2050-7d7b-4c4d-8354-29d00f39c278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this was the most i'd laughed at one of woody's comedies in years \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6e629-c5a0-4926-ac3e-c6c16cd86f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78c4fc87-f05b-481c-b2ec-f82bbcbd3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)   ### it apply this function to every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0855408f-e49b-4449-9873-a17755d048a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcfbb5-18ad-436e-b534-d041e746c48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8510151-9468-4618-9d56-14d2f9e687cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26487c78-1b56-433f-8655-c4462df9b29a",
   "metadata": {},
   "source": [
    "#### Remove url using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892878d-58fc-499c-8ad8-2056fbca2d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc72862d-19e0-45d3-be2f-0e7d18fac20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+') # fing this pattern online\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24759c8e-3fba-4295-9fb0-ec842749dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1='i am darshan and here is https://www.youtube.com/watch?v=6C0sLtw5ctc&list=PLKnIA16_RmvZo7fp5kkIth6nRTeQQsjfX&index=3'\n",
    "text2='very long busy day of https://colab.research.google.com/drive/1x-L_g8MFTahkC5c4T4f482kS9GL5LBGS#scrollTo=hHqoyB8FUlsJ'\n",
    "text3='so long ago www.verylong.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fbfd0e2-5829-4b54-b57a-433557002855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am darshan and here is '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dec71c9d-75f1-48af-bee7-dc280b34d01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'very long busy day of '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "514e745e-b2fe-4ee0-9807-ffc553e46a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so long ago '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61894933-d09d-455b-83de-63d31d6bdf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45b0c6-aa5d-450d-8999-05fd1df29d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98ba6688-c861-4caa-bb28-4860a375b8ae",
   "metadata": {},
   "source": [
    "##### Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89c392-1699-45c9-a3b5-e4069c5ca15e",
   "metadata": {},
   "source": [
    "we need to remove punction because if we don't then either it consider as a single token which increase the size\n",
    "or it merge with word \n",
    "eg Hello ! how are you ?\n",
    "-> Hello, ! , how , are , you , ? => more token generated \n",
    "-> Hello !, how , are,  you?  => Hello and Hello! are not same which confuse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e703800-4a02-4e04-b617-c4776fb5844b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12b5fd41-b907-42a9-ac6e-37450574fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82b604f6-23cb-4d44-9241-bb85e4284323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "004869fd-3d04-45b8-9dc2-ee57e10c2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fca7180-f993-4556-8521-f630c824c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text\n",
    "# it is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "615f2e6f-30ed-4d91-b8da-8ef3aa174d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1= 'Hello ! how are you ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df1d2581-5116-4cad-81d8-2255e0bce938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello  how are you '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_puc(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3377d6c7-120a-4856-92d7-1dec299d2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puch1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62c18035-72ca-4b28-a3e4-2293ca436c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello  how are you '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_puch1(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed694d-ff9e-499e-bce7-ad58a912f47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6ccab-0c00-4eee-804a-df8762b47391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8e1c94-7414-4a4f-9dda-254eed183593",
   "metadata": {},
   "source": [
    "#### Chat word removal like lmao igf wbu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0a64e-7ca1-4c3c-a5d7-ef8e1da639af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed79eb2-b970-47c6-a76b-4ba43eca701f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a818d386-c923-48cc-859a-3ee6d2a7a577",
   "metadata": {},
   "source": [
    "#### Spelling Correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38290d06-4216-4673-9eec-5efcdf03a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee45cbe5-e2f2-4307-851f-77540ec23749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello i am here to announce god morning to all'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text='hello i am heree to anounch gud morning to all'\n",
    "textblb=TextBlob(incorrect_text)\n",
    "textblb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4011d7b-95c7-4ed0-9fe0-561990e06f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c62e1dc-ff18-4499-a8f6-1166578b6aa3",
   "metadata": {},
   "source": [
    "### Remove stop word by nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bdd99-00ba-4db7-b35d-a6fc4e6662a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4ef474e-f09f-4974-a8f4-ccd7615c73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78104e44-a720-4757-88ee-13fec7310c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290cc983-ab35-4d5b-90a6-5a7f271f904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT =>  stop_words = set(stopwords.words('english'))   # load once, use as set for O(1) lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1075538c-2901-4c41-b37f-8221cd586992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82a98563-a8f0-4935-9c86-e909bab4e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    tell      shit    batman    time favourate movie'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopword(\"i am here to tell that i can do this shit by myself because batman is my all time favourate movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b157f-12f3-40bb-9c75-43883aea317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'].apply(remove_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f991c3-d919-46f2-b2d4-217789b47471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a7bcc0-a9e1-4670-9d96-10149fc2301a",
   "metadata": {},
   "source": [
    " ### Handling emoji either remove or replce with word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "63244a0d-2e42-4db3-8a18-aa4690f4764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a496efb6-ad20-45f8-bcc6-304e96f72053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is :face_with_tears_of_joy::face_with_tears_of_joy:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('python is ðŸ˜‚ðŸ˜‚'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811401c-a53c-4437-b79f-699cd6520d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74167289-e34a-45b3-a4f4-7051bd5b4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e841efb9-7855-4ec5-b972-440c80f6ce16",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2073709-7ca5-490d-9990-9ab892ca5111",
   "metadata": {},
   "source": [
    "challenges in tokenizations are \n",
    "1. Prefix\n",
    "2. Suffix\n",
    "3. infix\n",
    "4. exceptions\n",
    "eg. $10 ->  $ ,10\n",
    "    10 km -> 10 ,km should tokenize like this\n",
    "   which is defficult for algo\n",
    "   let's -> let us\n",
    "   U.S ->U.S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c1215-a459-4dc0-b962-c988b7e56cc4",
   "metadata": {},
   "source": [
    "##### 1. Using the split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b29d194-adcd-49f9-b787-9cb03986f7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1= \"I am going to delhi\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48a8f4ab-f7ae-4486-9403-39037b42018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going ton delhi', ' UI will stay there for 2 days']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence tokeization\n",
    "sent2=\"I am going ton delhi. UI will stay there for 2 days\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ee15199-34c6-41a0-9d81-28466024357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with split function\n",
    "sent3='I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9d294ab-4a36-430b-aae3-78cacbb9385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where do you think i should go? I have 3 days']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4='where do you think i should go? I have 3 days'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940aa48-01ae-4499-aa30-143fa8a65437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6547b35-23b3-49d8-b259-f1c364c1578d",
   "metadata": {},
   "source": [
    "##### 2.Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b7e16e8-8bbf-4886-8146-ac0cbfda4e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_27832\\2998769484.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  tokens=re.findall(\"[\\w']+\",sent3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "sent3='I am going to delhi!'\n",
    "tokens=re.findall(\"[\\w']+\",sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4210b7-60b5-40c0-9f27-abef4e98f032",
   "metadata": {},
   "source": [
    "##### 3.NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48f59142-6207-483c-8443-23793fefb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "daf5f6f3-235d-432d-8f52-ac367d4190cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi', '!']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3='I am going to delhi!'\n",
    "word_tokenize(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b1d05e2e-684c-4da8-a995-e171a65bd235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where do you think i should go?', 'I have 3 days']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4='where do you think i should go? I have 3 days'\n",
    "sent_tokenize(sent4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d987cc63-1193-466f-8b47-23531f4d2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5='I have a Ph.D in A.I'\n",
    "sent6=\"We're here to help! mail at rrr@gmail.com \"\n",
    "sent7=\"A 5km ride cost $10.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f07fb47b-4293-4428-a06a-35ce1ad92374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent5)  ## work perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b758d665-4004-4529-a3ad-81597eb72298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', \"'re\", 'here', 'to', 'help', '!', 'mail', 'at', 'rrr', '@', 'gmail.com']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)  ### divide the gmail it shoould be one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1ad4a04-508a-4293-8fcb-d75d3099b75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.5']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)  # 5km should be 2 tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92728d71-1e4f-47db-94ba-8ab621a28dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7cd98c-ee41-41b5-a562-6e30b9ebd221",
   "metadata": {},
   "source": [
    "##### 4. Spacy  nlp library where we load a english decetanory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0361af-ab1d-4fb1-9ba6-7b410a86194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f1196-50fc-4329-b090-350f0f52ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1= nlp(sent5)\n",
    "doc2=nlp(sent6)\n",
    "doc3=nlp(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2c3c7-32e1-4cda-895a-1dc06e60eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d9723-2e39-40a8-a8e1-40120a135488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5918041-e6c9-47fe-87f7-7cbc318dfa2e",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1708d-28f9-4f72-b192-eba92dc1ba77",
   "metadata": {},
   "source": [
    " infection in grammer is the modification of word to \n",
    " express diffenet grammatical catoegiers\n",
    " eg. walk-> walking waked waks\n",
    "      do -> undoable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e469f4-53d3-44fa-b783-f17e91a9e545",
   "metadata": {},
   "source": [
    "Steamming is process of reducing iniflection in word to their root forms such as mapping a group of word to the same stem even if the stem itself is not valid word in language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d352119-f2d1-4fcf-9887-026ebcfc18ce",
   "metadata": {},
   "source": [
    "\n",
    "Steaming is most use in Information Retrival system\n",
    "like google search engine where when we search \n",
    "word like fish fishing fishnet it give a mix ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9610913-3c90-4199-84c7-5c0a8408cab6",
   "metadata": {},
   "source": [
    "Different stammer use for steaming \n",
    "like portal stammer, snow bond stammer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca18dee-9aa6-499d-9e5e-738b458c6ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5490167a-941f-4817-92ce-1b56f1117f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe02eee3-3593-4d44-b085-754799e57099",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "28d03861-cd67-46cf-b136-05a521799190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e82c92-ef54-4cb3-a81a-7fee04a820c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47c9c41e-9526-4d96-b777-4834d6554eb6",
   "metadata": {},
   "source": [
    "#### Lemitization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8c8d7-f3ba-4c29-adae-1c1d4fab8166",
   "metadata": {},
   "source": [
    " Lemitization unlike stemming reduce the inflected word propley ensuring that the root word belong to the language.\n",
    "In emitization root word is called Lemma\n",
    "It use wordnet to find the word which make it slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "75f225d3-9c75-42d0-9de2-7a5de3afdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fffd8b33-27f9-48c3-98e0-8ef025be7171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'running',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'He',\n",
       " 'had',\n",
       " 'bad',\n",
       " 'habiit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'long',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "sentence='He was running and eating at the same time. He had bad habiit of swimming after playing long hours in the sun'\n",
    "punctuations=\"?:!,.;\"\n",
    "sentence_words=nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "sentence_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6ebf4-c9b3-4ed8-8e9d-c4416e47b714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
